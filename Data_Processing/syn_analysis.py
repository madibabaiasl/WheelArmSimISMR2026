# -*- coding: utf-8 -*-
"""syn_analysis_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hAN6Uf0XSL6bHoG-3XnSIZaBJKoGoaTE
"""

# -*- coding: utf-8 -*-
"""
syn_analysis_all_experiments.ipynb

Automatically generated by Colab.

Extends the data extraction and analysis to experiments 1..20.
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
import ast
import numpy as np
import matplotlib.pyplot as plt

# Headers to remove
headers_to_drop = [
    'processed_data_desired_pose', 'instructions',
    'processed_data_joint_state_back_left_wheel_joint_joint_name',
    'processed_data_joint_state_back_right_wheel_joint_joint_name',
    'processed_data_joint_state_front_left_wheel_joint_joint_name',
    'processed_data_joint_state_front_right_wheel_joint_joint_name',
    'processed_data_joint_state_joint_1_joint_name',
    'processed_data_joint_state_joint_2_joint_name',
    'processed_data_joint_state_joint_3_joint_name',
    'processed_data_joint_state_joint_4_joint_name',
    'processed_data_joint_state_joint_5_joint_name',
    'processed_data_joint_state_joint_6_joint_name',
    'processed_data_joint_state_left_inner_knuckle_finger_tip_joint_joint_name',
    'processed_data_joint_state_right_inner_knuckle_finger_tip_joint_joint_name',
    'processed_data_joint_state_robotiq_85_left_finger_tip_joint_joint_name',
    'processed_data_joint_state_robotiq_85_left_knuckle_joint_joint_name',
    'processed_data_joint_state_robotiq_85_right_finger_tip_joint_joint_name',
    'processed_data_joint_state_robotiq_85_right_knuckle_joint_joint_name'
]

# Columns that contain [time, data] and need to be split
time_added_headers = [
    'processed_data_cartesian_pose_bicep',
    'processed_data_cartesian_pose_end_effector',
    'processed_data_cartesian_pose_forearm',
    'processed_data_cartesian_pose_shoulder',
    'processed_data_cartesian_pose_spherical_wrist_1',
    'processed_data_cartesian_pose_spherical_wrist_2',
    'processed_data_cartesian_pose_wheelchair',
    'processed_data_cartesian_velocity_bicep',
    'processed_data_cartesian_velocity_end_effector',
    'processed_data_cartesian_velocity_forearm',
    'processed_data_cartesian_velocity_shoulder',
    'processed_data_cartesian_velocity_spherical_wrist_1',
    'processed_data_cartesian_velocity_spherical_wrist_2',
    'processed_data_cartesian_velocity_wheelchair',
    'processed_data_imu_angular_velocity',
    'processed_data_imu_linear_acceleration',
    'processed_data_imu_orientation',
    'processed_data_joint_state_back_left_wheel_joint',
    'processed_data_joint_state_back_right_wheel_joint',
    'processed_data_joint_state_front_left_wheel_joint',
    'processed_data_joint_state_front_right_wheel_joint',
    'processed_data_joint_state_joint_1',
    'processed_data_joint_state_joint_2',
    'processed_data_joint_state_joint_3',
    'processed_data_joint_state_joint_4',
    'processed_data_joint_state_joint_5',
    'processed_data_joint_state_joint_6',
    'processed_data_joint_state_left_inner_knuckle_finger_tip_joint',
    'processed_data_joint_state_right_inner_knuckle_finger_tip_joint',
    'processed_data_joint_state_robotiq_85_left_finger_tip_joint',
    'processed_data_joint_state_robotiq_85_left_knuckle_joint',
    'processed_data_joint_state_robotiq_85_right_finger_tip_joint',
    'processed_data_joint_state_robotiq_85_right_knuckle_joint'
]

# Time columns to extract into 'timesheet.csv'
extra_time_cols = [
    'processed_data_cameras_depth_gen3time',
    'processed_data_cameras_depth_wheelchairtime',
    'processed_data_cameras_rgb_gen3time',
    'processed_data_cameras_rgb_wheelchairtime',
    'processed_data_timesteps'
]

###############################################################################
# MAIN LOOP OVER EXPERIMENTS 1..20
###############################################################################
for n in range(1, 21):
    print("\n======================================")
    print(f"PROCESSING EXPERIMENT {n}")
    print("======================================")

    # 1) Read data_cleaned.csv if it exists
    csv_path = f'/content/drive/MyDrive/data/organization/picking/pick_mustard/Experiment{n}/data_cleaned.csv'
    if not os.path.exists(csv_path):
        print(f"CSV file not found for experiment {n}: {csv_path}")
        continue

    df = pd.read_csv(csv_path)

    # 2) Drop columns that we do not need
    for h in headers_to_drop:
        if h in df.columns:
            df.drop(columns=[h], inplace=True, errors='ignore')

    # 3) Convert each processed_data_* column from [time, data...] to separate columns
    for header in time_added_headers:
        if header not in df.columns:
            continue

        # Convert string to list if necessary
        df[header] = df[header].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

        # e.g. new header = "timestep_cartesian_pose_bicep" from "processed_data_cartesian_pose_bicep"
        new_header = header.replace("processed_data_", "timestep_")

        # The first element in each array is the time => place it in new_header
        df[new_header] = df[header].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)

        # Remove the first element from the original column => store only data
        df[header] = df[header].apply(lambda x: x[1:] if isinstance(x, list) and len(x) > 1 else [])

    # 4) Save as synchronise_analysis.csv
    out_csv_path = f'/content/drive/MyDrive/data/organization/picking/pick_mustard/Experiment{n}/synchronise_analysis.csv'
    df.to_csv(out_csv_path, index=False)
    print(f"Saved {out_csv_path}")

    # 5) Extract time columns into timesheet.csv
    #    For convenience, gather any column that starts with "timestep_" plus the extra_time_cols
    df_columns = df.columns.tolist()
    time_columns = [col for col in df_columns if col.startswith('timestep_')]

    # Also add the extra camera/sim time columns if present
    for etc in extra_time_cols:
        if etc in df_columns:
            time_columns.append(etc)

    # Create a new dataframe with just those time columns
    df_time = df[time_columns]

    time_csv_path = f'/content/drive/MyDrive/data/organization/picking/pick_mustard/Experiment{n}/timesheet.csv'
    df_time.to_csv(time_csv_path, index=False)
    print(f"Saved {time_csv_path}")

    # 6) (Optional) Example of analyzing delta time with simulation time
    #    We'll check if 'processed_data_timesteps' is there, and do some sample plots.
    if 'processed_data_timesteps' in df_time.columns:
        sim_time = df_time['processed_data_timesteps']
        sim_time_diff = sim_time.diff()

        # Plot the delta times
        plt.figure(figsize=(8, 4))
        plt.plot(sim_time_diff, marker='o', linestyle='-')
        plt.xlabel("Index")
        plt.ylabel("Delta Time")
        plt.title(f"Delta Time Between Consecutive Timestamps (Experiment {n})")
        plt.grid()
        plt.show()

        # You could repeat for other columns as well, or compare them to sim_time
        # e.g., compute diff from other columns:
        #    df_time["cartesian_sim_diff"] = df_time["timestep_cartesian_pose_bicep"] - sim_time
        #    etc.
    else:
        print("No 'processed_data_timesteps' column found. Skipping the delta-time plot.")

print("\nAll experiments processed!")
